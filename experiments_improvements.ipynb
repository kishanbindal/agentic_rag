{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd97055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\B'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\B'\n",
      "C:\\Users\\ANT-PC\\AppData\\Local\\Temp\\ipykernel_30156\\641077496.py:4: SyntaxWarning: invalid escape sequence '\\B'\n",
      "  processed_docs_path = \"C:\\BlueAI_bkp\\data\\processed\\wikiextractor\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "processed_docs_path = \"C:\\BlueAI_bkp\\data\\processed\\wikiextractor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7879ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenTelemetry Tracing Details\n",
      "|  Phoenix Project: Base-RAG\n",
      "|  Span Processor: BatchSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "# configure the Phoenix tracer\n",
    "tracer_provider = register(\n",
    "    project_name=\"Base-RAG\",                 # your project\n",
    "    endpoint=\"http://localhost:6006/v1/traces\",  # Phoenix Docker HTTP collector\n",
    "    protocol=\"grpc\",               # force HTTP instead of gRPC\n",
    "    auto_instrument=True,                   # auto-instrument LangChain + others\n",
    "    batch=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd33e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Iterator, Dict, Any, List\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# NEW\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "\n",
    "BASE_DIR = Path(\"data/processed/wikiextractor\")\n",
    "CHROMA_DIR = Path(\"chromadb\")\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5612fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f41c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from typing_extensions import Optional\n",
    "\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model, after_model\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7269f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChatAgentState(AgentState):\n",
    "    audit_state: Optional[bool]\n",
    "    audit_remarks: Optional[str]\n",
    "    initial_user_query: str\n",
    "    retrieval_query: Optional[str]\n",
    "    retrieved_docs: Optional[List[str]]\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-5\",   # or \"gpt-4o\", \"gpt-4.1-mini\", etc.\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a814fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def similarity_search_tool(state:ChatAgentState, query: str, k: int = 4, title:str | None = None) -> Tuple[str, List[Document]]:\n",
    "    \"\"\"\n",
    "    Retrieve documents similar to the query using the vector store.\n",
    "\n",
    "    Inputs: \n",
    "        1. Query(str) -> User query to perform vector search over vectorDB. \n",
    "        2. k:int (default 4) \n",
    "        3. title(str|None) -> title used for metadata filtering in the database.\n",
    "\n",
    "    Returns:\n",
    "        A (content, artifact) tuple:\n",
    "        - content: serialized text for the chat model\n",
    "        - artifact: raw List[Document] for downstream use / debugging\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "    print(F\"Input to Similarity search tool: {query}\")\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=\"chromadb\",\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=\"wiki_short_150\",\n",
    "    )\n",
    "    if title is None:\n",
    "        doc_score_pairs = vectordb.similarity_search_with_relevance_scores(\n",
    "            query=query,\n",
    "            k=k\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Title filter supplied: {title}\")\n",
    "        doc_score_pairs = vectordb.similarity_search_with_relevance_scores(\n",
    "            query=query,\n",
    "            k=k,\n",
    "            filter={\"title\": title}\n",
    "        )\n",
    "\n",
    "    docs: List[Document] = [doc for doc, _ in doc_score_pairs]\n",
    "\n",
    "    # 3) Serialize in an LLM-friendly, structured way\n",
    "    parts = []\n",
    "    for idx, (doc, score) in enumerate(doc_score_pairs, start=1):\n",
    "        part = (\n",
    "            f\"### Document {idx}\\n\"\n",
    "            f\"relevance_score: {score:.4f}\\n\"\n",
    "            f\"metadata: {doc.metadata}\\n\"\n",
    "            f\"content:\\n{doc.page_content}\\n\"\n",
    "        )\n",
    "        parts.append(part)\n",
    "\n",
    "    content_for_llm = \"\\n\\n\".join(parts) if parts else \"No documents found.\"\n",
    "\n",
    "    # 4) Return string for LLM + raw docs for downstream use\n",
    "    return {\n",
    "        \"retrieved_docs\": f\"{state['retrieved_docs']}\\n\\nRetrieval Query:{query}\\n{content_for_llm}\",\n",
    "        \"retrieval_query\": query\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9123c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_search_tool.run(\"Who was Julius Caesar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4905b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage, ToolMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "auditor_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Your role is to audit a given retrieval question and determine whether the retrieval query (and its parameters) are sufficient to obtain meaningful results from the similarity_search_tool.\n",
    "If not, you must suggest precise modifications that will improve retrieval.\n",
    "\n",
    "You are NOT judging whether the retrieved content is perfectly factually correct in the real world.\n",
    "You are ONLY judging whether the retrieved content is thematically relevant and provides some usable signal for the model to attempt an answer.\n",
    "\n",
    "#### Description of similarity_search_tool:\n",
    "- Inputs: retrieval_query (required), k (optional), title (optional).\n",
    "- The tool returns top-k most similar chunks from the vector database.\n",
    "- 'title' filters results by metadata, helping group related documents.\n",
    "- Your job is to improve the retrieval query when needed.\n",
    "\n",
    "#### Inputs:\n",
    "retrieval_query used: {retrieval_query}\n",
    "previous_tool_runs (tool outputs): {tool_messages}\n",
    "\n",
    "#### Internal Reasoning Style (Chain-of-Thought):\n",
    "- First, briefly reason about:\n",
    "  - What the retrieval_query is trying to get.\n",
    "  - Whether the retrieved chunks are on the same topic or closely related topics.\n",
    "  - Whether there is at least some useful information that the model could use to form a partial or approximate answer.\n",
    "- You should be tolerant of approximate or partially overlapping context.\n",
    "  - Example: If the query is about “the last battle of Caesar” and the retrieved chunks talk about the “Battle of Munda” within the broader Caesar campaigns, treat this as relevant context, not a failure, even if there are nuances about campaigns like Pharsalus.\n",
    "- Only consider it a failure if:\n",
    "  - The chunks are clearly off-topic or unrelated, OR\n",
    "  - There is essentially no substantive information that could help answer the query.\n",
    "\n",
    "Keep your reasoning short (2–4 sentences) and do NOT include external world knowledge beyond what is implied by the query and tool outputs.\n",
    "\n",
    "#### Rules:\n",
    "1. You must ONLY analyze the retrieval_query and the tool outputs (previous_tool_runs).\n",
    "2. DO NOT invent new knowledge about the world or query subject.\n",
    "3. Determine whether the retrieved context (seen in previous_tool_runs) is reasonably sufficient to let the model attempt an answer:\n",
    "   - If at least one or two chunks are on-topic and contain some relevant information, even if incomplete or not perfectly aligned, treat this as sufficient.\n",
    "   - Only mark as insufficient when the retrieved chunks are mostly or entirely irrelevant, empty, or contain no usable signal.\n",
    "4. If sufficient → audit_state = true and audit_remarks = \"Successful\".\n",
    "5. If insufficient → audit_state = false and audit_remarks must contain:\n",
    "     - The specific issue (e.g., missing title, query too broad, irrelevant results, too few retrieved chunks).\n",
    "     - A concrete suggestion on how to modify the retrieval_query, title, or k (e.g., “increase k from 4 to 10”, “add a title filter related to ‘Roman Empire’”, “make the query more specific to XYZ”).\n",
    "\n",
    "#### Output Format (JSON only):\n",
    "{{\n",
    "  \"audit_state\": true | false,\n",
    "  \"audit_remarks\": \"Successful\" | \"Failure: <explanation + suggested changes>\"\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "@tool\n",
    "def audit_node(state: ChatAgentState):\n",
    "    \"\"\"\n",
    "    Tool is used to Audit the status of a response, specifically in scenarios where it returns I don't know or is unable to answer. \n",
    "    \"\"\"\n",
    "    chat_history = state['messages']\n",
    "    latest_ai_message = \"\"\n",
    "    for message in chat_history:\n",
    "        if isinstance(message, AIMessage):\n",
    "            latest_ai_message=message\n",
    "    # tool_messages = [\n",
    "    # msg for msg in chat_history\n",
    "    # if isinstance(msg, ToolMessage) and msg.name == \"similarity_search_tool\"\n",
    "    # ]\n",
    "    tool_messages = state['retrieved_docs']\n",
    "\n",
    "    chain = auditor_prompt | model | JsonOutputParser()\n",
    "\n",
    "    output = chain.invoke({\n",
    "        \"initial_user_query\": state['initial_user_query'],\n",
    "        \"retrieval_query\": state['retrieval_query'],\n",
    "        \"tool_messages\": tool_messages,\n",
    "    })\n",
    "    print(\"Auditor Ouptut: \",output)\n",
    "    # print(f\"{output['messages'][0].content}\")\n",
    "    return {\n",
    "        \"audit_state\": output['audit_state'],\n",
    "        \"audit_remarks\": output['audit_remarks']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "332bc0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audit_node(\"What river did he cross?\",\"turn 1: Caesar was a king. turn 2: I dont know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c48959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19555f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@before_model\n",
    "def pre_model(state: ChatAgentState, runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Runs before the LLM is called.\n",
    "    You can:\n",
    "      - trim / summarize messages\n",
    "      - inject extra context\n",
    "      - modify state[\"remaining_steps\"], etc.\n",
    "    Return a partial state update or None for no-op.\n",
    "    \"\"\"\n",
    "    # Example NO-OP (scaffolding only)\n",
    "    # You could, for example, keep only the last N messages here.\n",
    "    return None\n",
    "\n",
    "\n",
    "@after_model\n",
    "def post_model(state: ChatAgentState, runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Runs after the LLM responds (but before tools run again).\n",
    "    You can:\n",
    "      - validate / edit model output\n",
    "      - add guardrails\n",
    "      - log things\n",
    "    Return a partial state update or None for no-op.\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# --- 5. Build the agent -------------------------------------------------------\n",
    "tools = [similarity_search_tool, audit_node]\n",
    "\n",
    "# #### Rules: \n",
    "# 1. You cannot answer from beyond the retrieved documents. \n",
    "# 2. Use the similarity_search_tool when you need documents to answer a user's question. DO NOT embellish the question with your own knowledge. All knwoledge must come from chat history and retreived documents                 \n",
    "# 3. When the retrieved documents do not contain the data to a question, use the auditor tool and audit remarks to improve the query being sent to the similarity_search_tool. \n",
    "# 4. Always provide the title and url as wel as the chunk_index of the passage that is being used. \n",
    "# 5. Provide the user's query directly to the similiarty_search_tool\n",
    "# 6. Once audit status turns to True, you can end the process\n",
    "\n",
    "# #### Situations where context is you are unable to answer a question\n",
    "# 1. Call the RAG Auditor tool. Rephrase the question based on Audit and provide the answer \n",
    "# 2. Retry a maximum of 2 times, If data is not found, return with \"I am sorry, I am unable to answer the question.\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "#### Role: \n",
    "- You are a chat assistant that is developed to answer the user's question. \n",
    "\n",
    "#### Rules: \n",
    "1. You cannot answer from beyond the retrieved documents.\n",
    "2. Pass the user's question to the similarity_search_tool, **DO NOT** use your own data while rephrasing questions. The rephrasing should be driven through Auditor feedback Or Previously messages ONLY.\n",
    "3. Get the output Auditted.\n",
    "4. Once Audit Status is True, provide your output\n",
    "5. Always provide the title and url as wel as the chunk_index of the passage that is being used. \n",
    "\n",
    "## Examples\n",
    "#### Example 1: \n",
    "\n",
    "\n",
    "Inputs: \n",
    "Initial user query: {initial_user_query}\n",
    "Audit Status: {audit_status}\n",
    "Audit Remarks: {audit_remarks}\n",
    "\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    state_schema=ChatAgentState,          # ensures state has messages + remaining_steps\n",
    "    middleware=[pre_model, post_model], # hooks for future context management\n",
    "    checkpointer=checkpointer,          # short-term memory (thread-scoped)\n",
    ")\n",
    "\n",
    "# @tool\n",
    "# def audit_node(state: )\n",
    "\n",
    "# --- 6. Simple helper for calling the agent -----------------------------------\n",
    "def run_agent(user_query: str, thread_id: str = \"default\") -> str:\n",
    "    \"\"\"\n",
    "    Thin wrapper to send a message into the agent and get the final reply content.\n",
    "    `thread_id` controls the short-term memory thread.\n",
    "    \"\"\"\n",
    "    config: RunnableConfig = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    state = agent.invoke(\n",
    "        {\n",
    "            \"initial_user_query\": user_query,\n",
    "        },\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    final_msg = state[\"messages\"][-1]\n",
    "    return final_msg.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6ee2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_agent(\"What's so special about this letter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83529e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- State scaffold (adapt to your AgentState if you have a TypedDict) ---\n",
    "\n",
    "from langchain.messages import AIMessage\n",
    "\n",
    "\n",
    "def make_initial_state(max_steps: int = 8) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"messages\": [],          # type: list[BaseMessage]\n",
    "        \"remaining_steps\": max_steps,\n",
    "        'audit_status': None,\n",
    "        \"audit_remarks\": None,\n",
    "        \"initial_user_query\": \"\"\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Single turn runner (with checkpointer config) ---\n",
    "\n",
    "def run_one_turn(\n",
    "    agent,\n",
    "    state: Dict[str, Any],\n",
    "    thread_id: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Runs a single 'turn' of your agent given the current state.\n",
    "    Adds the required LangGraph config for the checkpointer.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            # add \"checkpoint_ns\" or \"checkpoint_id\" here if your graph needs them\n",
    "        }\n",
    "    }\n",
    "\n",
    "    new_state = agent.invoke(state, config=config)\n",
    "    return new_state\n",
    "\n",
    "\n",
    "# --- Turn-based conversation over a list of questions ---\n",
    "\n",
    "def simulate_turn_based_conversation(\n",
    "    agent,\n",
    "    questions: List[str],\n",
    "    max_steps: int = 8,\n",
    "    thread_id: str | None = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    1. Creates an initial state.\n",
    "    2. For each question:\n",
    "       - appends a HumanMessage\n",
    "       - calls the agent\n",
    "       - prints the latest AIMessage\n",
    "    \"\"\"\n",
    "    if thread_id is None:\n",
    "        thread_id = f\"test-thread-{uuid.uuid4()}\"\n",
    "\n",
    "    state = make_initial_state(max_steps=max_steps)\n",
    "\n",
    "    for turn_idx, question in enumerate(questions, start=1):\n",
    "        print(f\"\\n========== TURN {turn_idx} ==========\")\n",
    "        print(f\"User: {question}\")\n",
    "\n",
    "        # append HumanMessage instead of dict\n",
    "        state[\"messages\"].append(HumanMessage(content=question))\n",
    "        state['initial_user_query'] = question\n",
    "\n",
    "        # run the agent for this turn\n",
    "        state = run_one_turn(agent, state, thread_id=thread_id)\n",
    "\n",
    "        # find the last AIMessage and print it\n",
    "        assistant_msgs = [m for m in state[\"messages\"] if isinstance(m, AIMessage)]\n",
    "        if assistant_msgs:\n",
    "            last_assistant = assistant_msgs[-1]\n",
    "            print(f\"Assistant: {last_assistant.content}\")\n",
    "        else:\n",
    "            print(\"Assistant: <no AIMessage found in state>\")\n",
    "\n",
    "        if \"remaining_steps\" in state:\n",
    "            print(f\"(remaining_steps: {state['remaining_steps']})\")\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "109318a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TURN 1 ==========\n",
      "User: Who was Julius Caesar?\n",
      "Input to Similarity search tool: Who was Julius Caesar?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANT-PC\\AppData\\Local\\Temp\\ipykernel_30156\\1479069591.py:24: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auditor Ouptut:  {'audit_state': True, 'audit_remarks': 'Successful'}\n",
      "Assistant: Gaius Julius Caesar (12 July 100 BC – 15 March 44 BC) was a Roman military commander, politician, and author at the end of the Roman Republic. He joined the First Triumvirate, later fought and won a civil war against Pompey the Great, and ruled as Roman dictator until his assassination on the Ides of March, 44 BC, at the Curia of Pompey in Rome. He is widely regarded as one of history’s greatest military commanders, and his name “Caesar” became a title for emperors, influencing words like Kaiser and Tsar.\n",
      "\n",
      "Sources used:\n",
      "- Title: Julius Caesar | URL: https://simple.wikipedia.org/wiki?curid=5940 | chunk_index: 0\n",
      "- Title: Julius Caesar | URL: https://simple.wikipedia.org/wiki?curid=5940 | chunk_index: 1\n",
      "- Title: Battle of Thapsus | URL: https://simple.wikipedia.org/wiki?curid=1006782 | chunk_index: 1\n",
      "\n",
      "========== TURN 2 ==========\n",
      "User: Which major battle marked the end of his civil war?\n",
      "Input to Similarity search tool: Which major battle marked the end of his civil war?\n",
      "Input to Similarity search tool: Which major battle marked the end of Julius Caesar's civil war?\n",
      "Auditor Ouptut:  {'audit_state': True, 'audit_remarks': 'Successful'}\n",
      "Assistant: The decisive battle of Caesar’s Civil War was the Battle of Pharsalus (9 August 48 BCE). However, his final major defeat of the remaining Optimates came later at the Battle of Thapsus (6 April 46 BC), after which he stood unchallenged.\n",
      "\n",
      "Sources used:\n",
      "- Title: Battle of Pharsalus | URL: https://simple.wikipedia.org/wiki?curid=266306 | chunk_index: 0\n",
      "- Title: Battle of Thapsus | URL: https://simple.wikipedia.org/wiki?curid=1006782 | chunk_index: 0\n",
      "- Title: Battle of Thapsus | URL: https://simple.wikipedia.org/wiki?curid=1006782 | chunk_index: 5\n",
      "- Title: Battle of Thapsus | URL: https://simple.wikipedia.org/wiki?curid=1006782 | chunk_index: 6\n",
      "\n",
      "========== TURN 3 ==========\n",
      "User: Without naming Caesar, tell me the river he famously crossed.\n",
      "Input to Similarity search tool: Without naming Caesar, tell me the river he famously crossed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected either a dictionary with a 'type' key or an object with a 'type' attribute. Instead got type <class 'dict'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m      1\u001b[39m questions = [\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# --- PHASE 1: History Base Context ---\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWho was Julius Caesar?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinally, relate that oldest entity to the theme of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpower\u001b[39m\u001b[33m'\u001b[39m\u001b[33m we discussed in one of the earlier topics.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m final_state = \u001b[43msimulate_turn_based_conversation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdev-session-2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or let it auto-generate\u001b[39;49;00m\n\u001b[32m     82\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36msimulate_turn_based_conversation\u001b[39m\u001b[34m(agent, questions, max_steps, thread_id)\u001b[39m\n\u001b[32m     64\u001b[39m state[\u001b[33m'\u001b[39m\u001b[33minitial_user_query\u001b[39m\u001b[33m'\u001b[39m] = question\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# run the agent for this turn\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m state = \u001b[43mrun_one_turn\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# find the last AIMessage and print it\u001b[39;00m\n\u001b[32m     70\u001b[39m assistant_msgs = [m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, AIMessage)]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mrun_one_turn\u001b[39m\u001b[34m(agent, state, thread_id)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03mRuns a single 'turn' of your agent given the current state.\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03mAdds the required LangGraph config for the checkpointer.\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m config = {\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: thread_id,\n\u001b[32m     30\u001b[39m         \u001b[38;5;66;03m# add \"checkpoint_ns\" or \"checkpoint_id\" here if your graph needs them\u001b[39;00m\n\u001b[32m     31\u001b[39m     }\n\u001b[32m     32\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m new_state = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:799\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, runtime)\u001b[39m\n\u001b[32m    797\u001b[39m input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_calls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_runtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combine_tool_outputs(outputs, input_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\concurrent\\futures\\_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\concurrent\\futures\\_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:551\u001b[39m, in \u001b[36mContextThreadPoolExecutor.map.<locals>._wrapped_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_fn\u001b[39m(*args: Any) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontexts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:1010\u001b[39m, in \u001b[36mToolNode._run_one\u001b[39m\u001b[34m(self, call, input_type, tool_runtime)\u001b[39m\n\u001b[32m   1006\u001b[39m config = tool_runtime.config\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_tool_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1009\u001b[39m     \u001b[38;5;66;03m# No wrapper - execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tool_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[38;5;66;03m# Define execute callable that can be called multiple times\u001b[39;00m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(req: ToolCallRequest) -> ToolMessage | Command:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:959\u001b[39m, in \u001b[36mToolNode._execute_tool_sync\u001b[39m\u001b[34m(self, request, input_type, config)\u001b[39m\n\u001b[32m    956\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    958\u001b[39m     \u001b[38;5;66;03m# Error is handled - create error ToolMessage\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m     content = \u001b[43m_handle_tool_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_tool_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ToolMessage(\n\u001b[32m    961\u001b[39m         content=content,\n\u001b[32m    962\u001b[39m         name=call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    963\u001b[39m         tool_call_id=call[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    964\u001b[39m         status=\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    965\u001b[39m     )\n\u001b[32m    967\u001b[39m \u001b[38;5;66;03m# Process successful response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:424\u001b[39m, in \u001b[36m_handle_tool_error\u001b[39m\u001b[34m(e, flag)\u001b[39m\n\u001b[32m    422\u001b[39m     content = flag\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(flag):\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     content = \u001b[43mflag\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore [assignment, call-arg]\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     msg = (\n\u001b[32m    427\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot unexpected type of `handle_tool_error`. Expected bool, str \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mor callable. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:381\u001b[39m, in \u001b[36m_default_handle_tool_errors\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ToolInvocationError):\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m e.message\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:916\u001b[39m, in \u001b[36mToolNode._execute_tool_sync\u001b[39m\u001b[34m(self, request, input_type, config)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    915\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m         response = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    918\u001b[39m         \u001b[38;5;66;03m# Filter out errors for injected arguments\u001b[39;00m\n\u001b[32m    919\u001b[39m         injected = \u001b[38;5;28mself\u001b[39m._injected_args.get(call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:605\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    597\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    599\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    602\u001b[39m     **kwargs: Any,\n\u001b[32m    603\u001b[39m ) -> Any:\n\u001b[32m    604\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:931\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    930\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    932\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    933\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:890\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    888\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    893\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    894\u001b[39m         tool_kwargs |= {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:793\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    786\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    787\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    790\u001b[39m ):\n\u001b[32m    791\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    792\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    795\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:672\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    670\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    671\u001b[39m             tool_input[k] = tool_call_id\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     result = \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    673\u001b[39m     result_dict = result.model_dump()\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# Check args_schema for InjectedToolCallId\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\BlueAI_bkp\\venv\\Lib\\site-packages\\langchain_core\\messages\\utils.py:71\u001b[39m, in \u001b[36m_get_type\u001b[39m\u001b[34m(v)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m v.type\n\u001b[32m     67\u001b[39m msg = (\n\u001b[32m     68\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected either a dictionary with a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m\u001b[33m key or an object \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m\u001b[33m attribute. Instead got type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[31mTypeError\u001b[39m: Expected either a dictionary with a 'type' key or an object with a 'type' attribute. Instead got type <class 'dict'>.",
      "During task with name 'tools' and id 'e121e871-ea58-d9f5-0aa7-9415dc03e7d9'"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    # --- PHASE 1: History Base Context ---\n",
    "    \"Who was Julius Caesar?\",\n",
    "    \"Which major battle marked the end of his civil war?\",\n",
    "    \"Without naming Caesar, tell me the river he famously crossed.\",\n",
    "    \n",
    "    # --- PHASE 2: Geography Shift ---\n",
    "    \"What is the capital of Argentina?\",\n",
    "    \"Name one UNESCO World Heritage site in that country.\",\n",
    "    \"Compare the population of Buenos Aires to the city where Caesar was assassinated.\",\n",
    "    \n",
    "    # --- PHASE 3: Science Injection ---\n",
    "    \"What is the chemical formula of water?\",\n",
    "    \"What property of water allows insects like water striders to walk on its surface?\",\n",
    "    \"Is that property more related to cohesion or adhesion?\",\n",
    "    \n",
    "    # --- PHASE 4: Literature Divergence ---\n",
    "    \"Who wrote 'Pride and Prejudice'?\",\n",
    "    \"Without naming the author, describe the central theme.\",\n",
    "    \"Does that theme relate in any way to the political alliances Caesar formed?\",\n",
    "    \n",
    "    # --- PHASE 5: Return to Geography ---\n",
    "    \"Earlier we spoke about a capital city. Which city was it?\",\n",
    "    \"Now tell me one major river running through that city.\",\n",
    "    \n",
    "    # --- PHASE 6: Animals / Biology ---\n",
    "    \"What is the largest species of shark?\",\n",
    "    \"Where in the world's oceans is it most commonly found?\",\n",
    "    \"Compare the size of this shark to the height of the tallest mountain in the world.\",\n",
    "    \n",
    "    # --- PHASE 7: Aviation ---\n",
    "    \"What is the Boeing 747 commonly nicknamed?\",\n",
    "    \"Which airline was the first to operate it commercially?\",\n",
    "    \"How does its typical cruising altitude compare to the elevation of Mount Everest?\",\n",
    "    \n",
    "    # --- PHASE 8: Sports ---\n",
    "    \"Who holds the record for the most goals in World Cup history?\",\n",
    "    \"Which national team did he represent?\",\n",
    "    \"Does that team share a continent with the capital city we mentioned earlier?\",\n",
    "    \n",
    "    # --- PHASE 9: Return to Early Context ---\n",
    "    \"Back to chemistry: what is the pH of pure water at room temperature?\",\n",
    "    \"And how does that compare to the acidity of lemon juice?\",\n",
    "    \n",
    "    # --- PHASE 10: Movies ---\n",
    "    \"Who directed the movie 'Inception'?\",\n",
    "    \"Name one major theme of this film.\",\n",
    "    \"Is that theme conceptually similar to the literary theme we discussed earlier?\",\n",
    "    \n",
    "    # --- PHASE 11: Space ---\n",
    "    \"What is the largest planet in our solar system?\",\n",
    "    \"What is the name of its most famous storm?\",\n",
    "    \"Is that storm larger or smaller than Earth?\",\n",
    "    \n",
    "    # --- PHASE 12: Politics / Return to Caesar ---\n",
    "    \"Which Roman leader succeeded Caesar as the first Emperor?\",\n",
    "    \"What relationship did he have with Caesar?\",\n",
    "    \"Does this familial relationship relate to any theme discussed in the novel earlier?\",\n",
    "    \n",
    "    # --- PHASE 13: Mathematics ---\n",
    "    \"What is the value of Pi rounded to 5 decimal places?\",\n",
    "    \"Is Pi a rational or irrational number?\",\n",
    "    \"Compare this mathematical concept to the precision required in aviation altimeters.\",\n",
    "    \n",
    "    # --- PHASE 14: Companies / Technology ---\n",
    "    \"Who founded Microsoft?\",\n",
    "    \"Which operating system became its early mainstream success?\",\n",
    "    \"Is that operating system older or younger than the movie 'Inception'?\",\n",
    "    \n",
    "    # --- PHASE 15: FINAL CONTEXT STRESS ---\n",
    "    \"Earlier, we talked about an animal, a city, a storm, and a political alliance. List all four without explanation.\",\n",
    "    \"Now, from those four, which one existed first historically?\",\n",
    "    \"Finally, relate that oldest entity to the theme of 'power' we discussed in one of the earlier topics.\"\n",
    "]\n",
    "\n",
    "\n",
    "final_state = simulate_turn_based_conversation(\n",
    "    agent,\n",
    "    questions,\n",
    "    max_steps=8,\n",
    "    thread_id=\"dev-session-2\",  # or let it auto-generate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.get_state({\"configurable\": {\"thread_id\":\"dev-session-2\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.checkpointer.get({\"configurable\": {\"thread_id\": \"debug-thread-1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d7e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
